{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"316usman/tapal_validation_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity: 0.43750693180210043 for text  0\n",
      "Cosine similarity: 0.555235072783051 for text  1\n",
      "Cosine similarity: 0.5691937384575142 for text  2\n",
      "Cosine similarity: 0.6888458827873969 for text  3\n",
      "Cosine similarity: 0.5985592335367674 for text  4\n",
      "Cosine similarity: 0.5436390413166505 for text  5\n",
      "Cosine similarity: 0.6067193140570006 for text  6\n",
      "Cosine similarity: 0.5840404442010488 for text  7\n",
      "Cosine similarity: 0.7297276980311309 for text  8\n",
      "Cosine similarity: 0.41099546393495134 for text  9\n",
      "Cosine similarity: 0.5700963195527415 for text  10\n",
      "Cosine similarity: 0.6087744516418766 for text  11\n",
      "Cosine similarity: 0.5260416847752472 for text  12\n",
      "Cosine similarity: 0.7030435240462909 for text  13\n",
      "Cosine similarity: 0.5922632114243722 for text  14\n",
      "Cosine similarity: 0.5905203852841443 for text  15\n",
      "Cosine similarity: 0.6019712256947638 for text  16\n",
      "Cosine similarity: 0.6079982783632546 for text  17\n",
      "Cosine similarity: 0.587343786073001 for text  18\n",
      "Cosine similarity: 0.20043759373805609 for text  19\n",
      "Cosine similarity: 0.3521285263821744 for text  20\n",
      "Cosine similarity: 0.4157692097271685 for text  21\n",
      "Cosine similarity: 0.3582930615662151 for text  22\n",
      "Cosine similarity: 0.6129995323319367 for text  23\n",
      "Cosine similarity: 0.3467732312661961 for text  24\n",
      "Cosine similarity: 0.0 for text  25\n",
      "Cosine similarity: 0.24560346846205128 for text  26\n",
      "Cosine similarity: 0.7048615571857764 for text  27\n",
      "Cosine similarity: 0.20100496830616438 for text  28\n",
      "Cosine similarity: 0.4999795079111168 for text  29\n",
      "Cosine similarity: 0.5243885111312836 for text  30\n",
      "Cosine similarity: 0.18022545610114665 for text  31\n",
      "Cosine similarity: 0.6928485330916857 for text  32\n",
      "Cosine similarity: 0.6951235321924584 for text  33\n",
      "Cosine similarity: 0.7883748780908132 for text  34\n",
      "Cosine similarity: 0.3183659239990059 for text  35\n",
      "Cosine similarity: 0.6386835605473015 for text  36\n",
      "Cosine similarity: 0.7022729229195751 for text  37\n",
      "Cosine similarity: 0.42338816314383537 for text  38\n",
      "Cosine similarity: 0.4473452168966632 for text  39\n",
      "Cosine similarity: 0.47924746986254624 for text  40\n",
      "Cosine similarity: 0.6442226682262221 for text  41\n",
      "Cosine similarity: 0.4122327791351728 for text  42\n",
      "Cosine similarity: 0.4691216178951998 for text  43\n",
      "Cosine similarity: 0.4638602370680865 for text  44\n",
      "Cosine similarity: 0.4879795929643056 for text  45\n",
      "Cosine similarity: 0.31814421291111156 for text  46\n",
      "Cosine similarity: 0.4109679655930234 for text  47\n",
      "Cosine similarity: 0.4341567855425615 for text  48\n",
      "Cosine similarity: 0.5079864759740887 for text  49\n",
      "Cosine similarity: 0.5078744416723172 for text  50\n",
      "Cosine similarity: 0.7688376598848696 for text  51\n",
      "Cosine similarity: 0.551087419692595 for text  52\n",
      "Cosine similarity: 0.6656987097610786 for text  53\n",
      "Cosine similarity: 0.6559761143675097 for text  54\n",
      "Cosine similarity: 0.7617637421701073 for text  55\n",
      "Cosine similarity: 0.532766808976944 for text  56\n",
      "Cosine similarity: 0.6767751218924319 for text  57\n",
      "Cosine similarity: 0.6018574410095077 for text  58\n",
      "Cosine similarity: 0.03615569527156742 for text  59\n",
      "Cosine similarity: 0.5950569383947917 for text  60\n",
      "Cosine similarity: 0.6161184301857735 for text  61\n",
      "Cosine similarity: 0.44210754038602806 for text  62\n",
      "Cosine similarity: 0.8658477081305005 for text  63\n",
      "Cosine similarity: 0.4717194203200748 for text  64\n",
      "Cosine similarity: 0.5005045998114058 for text  65\n",
      "Cosine similarity: 0.6475366682356087 for text  66\n",
      "Cosine similarity: 0.6279007360434957 for text  67\n",
      "Cosine similarity: 0.6730741589004055 for text  68\n",
      "Cosine similarity: 0.45610020130509077 for text  69\n",
      "Cosine similarity: 0.2300049801371211 for text  70\n",
      "Cosine similarity: 0.5368342317114928 for text  71\n",
      "Cosine similarity: 0.49239421099199066 for text  72\n",
      "Cosine similarity: 0.6731073417091624 for text  73\n",
      "Cosine similarity: 0.5915869308639932 for text  74\n",
      "Cosine similarity: 0.17427843839641127 for text  75\n",
      "Cosine similarity: 0.6864077842639427 for text  76\n",
      "Cosine similarity: 0.6507925636683033 for text  77\n",
      "Cosine similarity: 0.7089384563848312 for text  78\n",
      "Cosine similarity: 0.5144031476979595 for text  79\n",
      "Cosine similarity: 0.5123766572226617 for text  80\n",
      "Cosine similarity: 0.490046073578752 for text  81\n",
      "Cosine similarity: 0.5762826075913903 for text  82\n",
      "Cosine similarity: 0.6479323522265262 for text  83\n",
      "Cosine similarity: 0.26508075569051553 for text  84\n",
      "Cosine similarity: 0.5901335792640571 for text  85\n",
      "Cosine similarity: 0.4858202384711494 for text  86\n",
      "Cosine similarity: 0.560647743179765 for text  87\n",
      "Cosine similarity: 0.287201069784867 for text  88\n",
      "Cosine similarity: 0.6416153709884989 for text  89\n",
      "Cosine similarity: 0.7060777744337089 for text  90\n",
      "Cosine similarity: 0.771362646148197 for text  91\n",
      "Cosine similarity: 0.5700476310912682 for text  92\n",
      "Cosine similarity: 0.46307954249262495 for text  93\n",
      "Cosine similarity: 0.46116812577933264 for text  94\n",
      "Cosine similarity: 0.6190892328274288 for text  95\n",
      "Cosine similarity: 0.4087580118567665 for text  96\n",
      "Cosine similarity: 0.8717945044342879 for text  97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "cosine_similarities = []\n",
    "\n",
    "for i in range (len(dataset['train'])):\n",
    "    text1 = dataset['train']['text'][i]\n",
    "    text2 = dataset['train']['generated_text_1'][i]\n",
    "\n",
    "    preprocessed_text1 = text1.lower().strip()\n",
    "    preprocessed_text2 = text2.lower().strip()\n",
    "\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform([preprocessed_text1, preprocessed_text2])\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)[0, 1]\n",
    "    cosine_similarities.append(cosine_sim)\n",
    "    # Print the cosine similarity score\n",
    "    print(\"Cosine similarity:\", cosine_sim , \"for text \", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#KhanayKayBaad #TapalGreenTea\n",
      "#KhanayKayB  *tou phir* Khanay Kay Baad... Tapal Green Tea please\n"
     ]
    }
   ],
   "source": [
    "print (dataset['train']['text'][25])\n",
    "print (dataset['train']['generated_text_1'][25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paise bachao aur Mega Bachat ka faida uthao. Order now!\n",
      "#MegaBachat #TapalFamilyMixture #MeriFamilyMeriStrength\n",
      "************\n",
      "Paise bachao aur Mega Bachat ka faida uthao. Order now!\n",
      "  Great! Here's how you can order and avail the Mega Bachat offer:\n",
      "\n",
      "1. Visit the Tapal Tea website: [www.tapaltea.com](http://www.tapaltea.com)\n",
      "2. Select your preferred product and quantity.\n",
      "3. Apply the Mega Bachat\n"
     ]
    }
   ],
   "source": [
    "print (dataset['train']['text'][20])\n",
    "print(\"************\")\n",
    "print (dataset['train']['generated_text_1'][20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fried food say ho jab skin compromise, aur detoxification karna paray prioritize. \n",
      "Tou Iftar kay baad Tapal Green Tea Please.\n",
      "\n",
      "Have Tapal Green Tea Elaichi and rejuvenate your body with a refreshing detox .\n",
      "\n",
      "#IftarKayBaad #TapalGreenTeaPlease\n",
      "\n",
      "Buy Now: https://bit.ly/2ElYrEG\n",
      "************\n",
      "Fried food say ho jab skin compromise, aur detoxification karna paray prioritize. \n",
      "Tou Iftar kay baad Tapal Green Tea Please.\n",
      "\n",
      "Have Tapal Green Tea Elaichi  Ahed Sehat, Aik Cup Chai\n",
      "Tumme Iftar Kay Baad Green Tea Please\n",
      "\n",
      "Tapal Green Tea Elaichi is a delicious and healthy beverage that you can enjoy after your meals to detoxify your body. It has no added flavors or colors, so you can be sure that you're getting only the goodness of green tea.\n",
      "\n",
      "Tapal Green Tea Elachi is made from the finest quality tea leaves that are carefully selected and processed to retain their natural goodness. It has a unique blend of green tea and Elachi that gives it a distinct taste and aroma.\n",
      "\n",
      "So, if you want to have a healthy and tasty beverage that can help you detoxify your body after your meals, then Tapal Green Tea Elaichi is the perfect choice for you.\n",
      "\n",
      "#TapalGreenTea #\n"
     ]
    }
   ],
   "source": [
    "print (dataset['train']['text'][38])\n",
    "print(\"************\")\n",
    "print (dataset['train']['generated_text_1'][38])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.73469387755102\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in cosine_similarities:\n",
    "    if i > 0.35:\n",
    "        count += 1\n",
    "print(count/len(cosine_similarities)* 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rouge Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1: Score(precision=0.84, recall=0.525, fmeasure=0.6461538461538462)\n",
      "rouge1: Score(precision=0.6222222222222222, recall=0.5656565656565656, fmeasure=0.5925925925925926)\n",
      "rouge1: Score(precision=0.8205128205128205, recall=0.5423728813559322, fmeasure=0.6530612244897959)\n",
      "rouge1: Score(precision=0.8571428571428571, recall=0.7741935483870968, fmeasure=0.8135593220338982)\n",
      "rouge1: Score(precision=0.78125, recall=0.8333333333333334, fmeasure=0.8064516129032259)\n",
      "rouge1: Score(precision=0.9130434782608695, recall=0.8076923076923077, fmeasure=0.8571428571428572)\n",
      "rouge1: Score(precision=0.7804878048780488, recall=0.6274509803921569, fmeasure=0.6956521739130435)\n",
      "rouge1: Score(precision=0.7333333333333333, recall=0.5789473684210527, fmeasure=0.6470588235294117)\n",
      "rouge1: Score(precision=0.8947368421052632, recall=0.8095238095238095, fmeasure=0.8500000000000001)\n",
      "rouge1: Score(precision=0.8, recall=0.7619047619047619, fmeasure=0.7804878048780488)\n",
      "rouge1: Score(precision=0.7073170731707317, recall=0.5576923076923077, fmeasure=0.6236559139784946)\n",
      "rouge1: Score(precision=0.8095238095238095, recall=0.7083333333333334, fmeasure=0.7555555555555556)\n",
      "rouge1: Score(precision=0.7, recall=0.4375, fmeasure=0.5384615384615384)\n",
      "rouge1: Score(precision=0.8333333333333334, recall=0.5263157894736842, fmeasure=0.6451612903225806)\n",
      "rouge1: Score(precision=0.8148148148148148, recall=0.44, fmeasure=0.5714285714285714)\n",
      "rouge1: Score(precision=0.8148148148148148, recall=0.6470588235294118, fmeasure=0.7213114754098361)\n",
      "rouge1: Score(precision=0.8260869565217391, recall=0.475, fmeasure=0.6031746031746033)\n",
      "rouge1: Score(precision=0.88, recall=0.6875, fmeasure=0.7719298245614036)\n",
      "rouge1: Score(precision=0.7105263157894737, recall=0.5869565217391305, fmeasure=0.6428571428571428)\n",
      "rouge1: Score(precision=0.7272727272727273, recall=0.41025641025641024, fmeasure=0.5245901639344261)\n",
      "rouge1: Score(precision=0.7692307692307693, recall=0.43478260869565216, fmeasure=0.5555555555555555)\n",
      "rouge1: Score(precision=0.6730769230769231, recall=0.4861111111111111, fmeasure=0.564516129032258)\n",
      "rouge1: Score(precision=0.7647058823529411, recall=0.6190476190476191, fmeasure=0.6842105263157895)\n",
      "rouge1: Score(precision=0.7407407407407407, recall=0.7407407407407407, fmeasure=0.7407407407407407)\n",
      "rouge1: Score(precision=0.8333333333333334, recall=0.5769230769230769, fmeasure=0.6818181818181818)\n",
      "rouge1: Score(precision=0.0, recall=0.0, fmeasure=0.0)\n",
      "rouge1: Score(precision=0.625, recall=0.3333333333333333, fmeasure=0.43478260869565216)\n",
      "rouge1: Score(precision=0.7222222222222222, recall=0.4642857142857143, fmeasure=0.5652173913043479)\n",
      "rouge1: Score(precision=0.6071428571428571, recall=0.4722222222222222, fmeasure=0.53125)\n",
      "rouge1: Score(precision=0.6296296296296297, recall=0.5, fmeasure=0.5573770491803278)\n",
      "rouge1: Score(precision=0.75, recall=0.6428571428571429, fmeasure=0.6923076923076924)\n",
      "rouge1: Score(precision=0.5666666666666667, recall=0.4473684210526316, fmeasure=0.5)\n",
      "rouge1: Score(precision=0.7419354838709677, recall=0.575, fmeasure=0.6478873239436619)\n",
      "rouge1: Score(precision=0.8333333333333334, recall=0.5882352941176471, fmeasure=0.6896551724137931)\n",
      "rouge1: Score(precision=0.8571428571428571, recall=0.631578947368421, fmeasure=0.7272727272727273)\n",
      "rouge1: Score(precision=0.7647058823529411, recall=0.48148148148148145, fmeasure=0.5909090909090909)\n",
      "rouge1: Score(precision=0.8, recall=0.6666666666666666, fmeasure=0.7272727272727272)\n",
      "rouge1: Score(precision=0.8095238095238095, recall=0.5483870967741935, fmeasure=0.6538461538461537)\n",
      "rouge1: Score(precision=0.6585365853658537, recall=0.54, fmeasure=0.5934065934065934)\n",
      "rouge1: Score(precision=0.72, recall=0.5625, fmeasure=0.631578947368421)\n",
      "rouge1: Score(precision=0.7692307692307693, recall=0.5555555555555556, fmeasure=0.6451612903225806)\n",
      "rouge1: Score(precision=0.84, recall=0.6774193548387096, fmeasure=0.75)\n",
      "rouge1: Score(precision=0.6451612903225806, recall=0.4878048780487805, fmeasure=0.5555555555555556)\n",
      "rouge1: Score(precision=0.8, recall=0.5555555555555556, fmeasure=0.6557377049180328)\n",
      "rouge1: Score(precision=0.8461538461538461, recall=0.6111111111111112, fmeasure=0.7096774193548387)\n",
      "rouge1: Score(precision=0.8333333333333334, recall=0.5172413793103449, fmeasure=0.6382978723404256)\n",
      "rouge1: Score(precision=0.7142857142857143, recall=0.4166666666666667, fmeasure=0.5263157894736842)\n",
      "rouge1: Score(precision=0.6666666666666666, recall=0.5, fmeasure=0.5714285714285715)\n",
      "rouge1: Score(precision=0.7692307692307693, recall=0.4878048780487805, fmeasure=0.5970149253731344)\n",
      "rouge1: Score(precision=0.8333333333333334, recall=0.5882352941176471, fmeasure=0.6896551724137931)\n",
      "rouge1: Score(precision=0.75, recall=0.5555555555555556, fmeasure=0.6382978723404256)\n",
      "rouge1: Score(precision=0.8024691358024691, recall=0.6132075471698113, fmeasure=0.6951871657754011)\n",
      "rouge1: Score(precision=0.6511627906976745, recall=0.5714285714285714, fmeasure=0.6086956521739131)\n",
      "rouge1: Score(precision=0.7954545454545454, recall=0.5737704918032787, fmeasure=0.6666666666666666)\n",
      "rouge1: Score(precision=0.8823529411764706, recall=0.7894736842105263, fmeasure=0.8333333333333333)\n",
      "rouge1: Score(precision=0.8125, recall=0.5416666666666666, fmeasure=0.65)\n",
      "rouge1: Score(precision=0.6666666666666666, recall=0.46153846153846156, fmeasure=0.5454545454545455)\n",
      "rouge1: Score(precision=0.8421052631578947, recall=0.6153846153846154, fmeasure=0.7111111111111111)\n",
      "rouge1: Score(precision=0.75, recall=0.5454545454545454, fmeasure=0.631578947368421)\n",
      "rouge1: Score(precision=0.2, recall=0.07142857142857142, fmeasure=0.10526315789473682)\n",
      "rouge1: Score(precision=0.88, recall=0.7096774193548387, fmeasure=0.7857142857142856)\n",
      "rouge1: Score(precision=0.6585365853658537, recall=0.5094339622641509, fmeasure=0.574468085106383)\n",
      "rouge1: Score(precision=0.7777777777777778, recall=0.5384615384615384, fmeasure=0.6363636363636364)\n",
      "rouge1: Score(precision=0.8947368421052632, recall=0.6071428571428571, fmeasure=0.7234042553191489)\n",
      "rouge1: Score(precision=0.8333333333333334, recall=0.5172413793103449, fmeasure=0.6382978723404256)\n",
      "rouge1: Score(precision=0.7333333333333333, recall=0.39285714285714285, fmeasure=0.5116279069767441)\n",
      "rouge1: Score(precision=0.782608695652174, recall=0.5294117647058824, fmeasure=0.631578947368421)\n",
      "rouge1: Score(precision=0.8181818181818182, recall=0.72, fmeasure=0.7659574468085107)\n",
      "rouge1: Score(precision=0.6142857142857143, recall=0.4725274725274725, fmeasure=0.5341614906832297)\n",
      "rouge1: Score(precision=0.7692307692307693, recall=0.5882352941176471, fmeasure=0.6666666666666667)\n",
      "rouge1: Score(precision=0.5862068965517241, recall=0.4722222222222222, fmeasure=0.523076923076923)\n",
      "rouge1: Score(precision=0.6923076923076923, recall=0.782608695652174, fmeasure=0.7346938775510203)\n",
      "rouge1: Score(precision=0.8518518518518519, recall=0.8518518518518519, fmeasure=0.8518518518518519)\n",
      "rouge1: Score(precision=0.8888888888888888, recall=0.7619047619047619, fmeasure=0.8205128205128205)\n",
      "rouge1: Score(precision=0.8076923076923077, recall=0.6176470588235294, fmeasure=0.7)\n",
      "rouge1: Score(precision=0.8, recall=0.41379310344827586, fmeasure=0.5454545454545454)\n",
      "rouge1: Score(precision=0.8571428571428571, recall=0.6666666666666666, fmeasure=0.75)\n",
      "rouge1: Score(precision=0.7777777777777778, recall=0.5185185185185185, fmeasure=0.6222222222222222)\n",
      "rouge1: Score(precision=0.7692307692307693, recall=0.5405405405405406, fmeasure=0.6349206349206349)\n",
      "rouge1: Score(precision=0.7419354838709677, recall=0.575, fmeasure=0.6478873239436619)\n",
      "rouge1: Score(precision=0.6071428571428571, recall=0.6296296296296297, fmeasure=0.6181818181818182)\n",
      "rouge1: Score(precision=0.6226415094339622, recall=0.5238095238095238, fmeasure=0.5689655172413793)\n",
      "rouge1: Score(precision=0.7407407407407407, recall=0.4878048780487805, fmeasure=0.588235294117647)\n",
      "rouge1: Score(precision=0.8064516129032258, recall=0.5319148936170213, fmeasure=0.641025641025641)\n",
      "rouge1: Score(precision=0.8125, recall=0.4642857142857143, fmeasure=0.5909090909090908)\n",
      "rouge1: Score(precision=0.7142857142857143, recall=0.5357142857142857, fmeasure=0.6122448979591837)\n",
      "rouge1: Score(precision=0.7692307692307693, recall=0.45454545454545453, fmeasure=0.5714285714285714)\n",
      "rouge1: Score(precision=0.7073170731707317, recall=0.6170212765957447, fmeasure=0.6590909090909092)\n",
      "rouge1: Score(precision=0.8095238095238095, recall=0.6071428571428571, fmeasure=0.6938775510204083)\n",
      "rouge1: Score(precision=0.7777777777777778, recall=0.5833333333333334, fmeasure=0.6666666666666666)\n",
      "rouge1: Score(precision=0.7647058823529411, recall=0.7647058823529411, fmeasure=0.7647058823529412)\n",
      "rouge1: Score(precision=0.7560975609756098, recall=0.8857142857142857, fmeasure=0.8157894736842105)\n",
      "rouge1: Score(precision=0.7857142857142857, recall=0.4782608695652174, fmeasure=0.5945945945945946)\n",
      "rouge1: Score(precision=0.8095238095238095, recall=0.5862068965517241, fmeasure=0.68)\n",
      "rouge1: Score(precision=0.7857142857142857, recall=0.6111111111111112, fmeasure=0.6875000000000001)\n",
      "rouge1: Score(precision=0.8076923076923077, recall=0.6176470588235294, fmeasure=0.7)\n",
      "rouge1: Score(precision=0.625, recall=0.47619047619047616, fmeasure=0.5405405405405405)\n",
      "rouge1: Score(precision=0.6812227074235808, recall=0.7090909090909091, fmeasure=0.6948775055679287)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dataset['train'])):\n",
    "    candidate = dataset['train']['text'][i]\n",
    "    reference = dataset['train']['generated_text_2'][i]\n",
    "    scores = scorer.score(reference, candidate)\n",
    "    for key in scores:\n",
    "        print(f'{key}: {scores[key]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
